{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8733847,"sourceType":"datasetVersion","datasetId":5242616}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":23.326866,"end_time":"2024-06-05T03:27:48.528599","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-05T03:27:25.201733","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The goal of this notebook is to replicate the process done during the FastAI cource to perform image recognition.  We will be evaluating whether or not we can train a model to detect if an image of a maze has been distorted to some effect. ","metadata":{"papermill":{"duration":0.002513,"end_time":"2024-06-05T03:27:47.325023","exception":false,"start_time":"2024-06-05T03:27:47.322510","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from fastcore.all import *\nfrom PIL import Image\nimport numpy as np\nfrom numpy import asarray\nimport pandas as pd","metadata":{"papermill":{"duration":0.13335,"end_time":"2024-06-05T03:27:47.461244","exception":false,"start_time":"2024-06-05T03:27:47.327894","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-21T15:15:52.837240Z","iopub.execute_input":"2024-06-21T15:15:52.838195Z","iopub.status.idle":"2024-06-21T15:15:52.850579Z","shell.execute_reply.started":"2024-06-21T15:15:52.838133Z","shell.execute_reply":"2024-06-21T15:15:52.848831Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = os.path.relpath(f\"/kaggle/input/grids-and-mazes/data/grid\")\nfiles = os.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:13:15.996192Z","iopub.execute_input":"2024-06-21T16:13:15.996621Z","iopub.status.idle":"2024-06-21T16:13:16.004923Z","shell.execute_reply.started":"2024-06-21T16:13:15.996590Z","shell.execute_reply":"2024-06-21T16:13:16.003654Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Using list as suggested here:\n# https://stackoverflow.com/questions/13784192/creating-an-empty-pandas-dataframe-and-then-filling-it\ndata = []\n\nfor item in files:\n    im = Image.open(f\"{path}/{item}\")\n    numpy_im = asarray(im)\n    series = pd.Series({'picture' : numpy_im, 'category' : f'{path.split(\"/\")[-1]}'}, index=['picture', 'category'])\n    data.append(series)\n    \nprint(data)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:17:48.826425Z","iopub.execute_input":"2024-06-21T16:17:48.826900Z","iopub.status.idle":"2024-06-21T16:18:49.573947Z","shell.execute_reply.started":"2024-06-21T16:17:48.826864Z","shell.execute_reply":"2024-06-21T16:18:49.572814Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"[picture     [[[255, 255, 255], [240, 240, 240], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [240, 240, 240], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[236, 236, 236], [255, 255, 255], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [252, 252, 252], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [252, 252, 252], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [240, 240, 240], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [249, 249, 249], [247, 247,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[236, 236, 236], [255, 255, 255], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [248, 248,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [240, 240, 240], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [240, 240, 240], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [250, 250, 250], [253, 253,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[250, 250, 250], [255, 255, 255], [243, 243,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [252, 252, 252], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[236, 236, 236], [255, 255, 255], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[244, 244, 244], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [250, 250, 250], [253, 253,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [240, 240, 240], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [252, 252, 252], [251, 251,...\ncategory                                                 grid\ndtype: object, picture     [[[255, 255, 255], [255, 255, 255], [255, 255,...\ncategory                                                 grid\ndtype: object, picture     [[[251, 251, 251], [255, 255, 255], [248, 248,...\ncategory                                                 grid\ndtype: object]\n","output_type":"stream"}]},{"cell_type":"code","source":"grids = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:19:06.641739Z","iopub.execute_input":"2024-06-21T16:19:06.642161Z","iopub.status.idle":"2024-06-21T16:19:06.651830Z","shell.execute_reply.started":"2024-06-21T16:19:06.642126Z","shell.execute_reply":"2024-06-21T16:19:06.650574Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:19:08.231817Z","iopub.execute_input":"2024-06-21T16:19:08.232229Z","iopub.status.idle":"2024-06-21T16:19:27.052679Z","shell.execute_reply.started":"2024-06-21T16:19:08.232196Z","shell.execute_reply":"2024-06-21T16:19:27.051442Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                                             picture\n0  [[[255, 255, 255], [240, 240, 240], [255, 255,...\n1  [[[255, 255, 255], [240, 240, 240], [255, 255,...\n2  [[[236, 236, 236], [255, 255, 255], [251, 251,...\n3  [[[255, 255, 255], [255, 255, 255], [255, 255,...\n4  [[[255, 255, 255], [252, 252, 252], [251, 251,...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>picture</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[[255, 255, 255], [240, 240, 240], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[[255, 255, 255], [240, 240, 240], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[[236, 236, 236], [255, 255, 255], [251, 251,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[[255, 255, 255], [252, 252, 252], [251, 251,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Wandering off the beaten path\nNormally following the Is it a [Bird Tutorial,](https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data) we would now download an image of a forest. \nIn this case however, we will be running random modifications to skew the images of the mazes.  The goal is to see if the model can detect visual abstractions to the dataset.  \n## Possible places to look at to develop this:\n- [OpenCV](https://docs.opencv.org/4.x/da/d6e/tutorial_py_geometric_transformations.html)\n- [Scikit-Image](https://scikit-image.org/)\n- In essence we would be applying randomized 3D Gradients to an image\n- [Gradients Wikipedia](https://en.wikipedia.org/wiki/Gradient)","metadata":{"papermill":{"duration":0.002965,"end_time":"2024-06-05T03:27:48.102325","exception":false,"start_time":"2024-06-05T03:27:48.099360","status":"completed"},"tags":[]}}]}